{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bank Customer Churn Prediction System**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scipy.stats import randint, uniform\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ML Models\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Plotting Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./datasets/churn_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: Fix the dataset\n",
    "#NOTE: This is a two databases combination problem not severe!\n",
    "dataset['Card Type '] = dataset['Card Type '].where(dataset['HasCrCard'] == 1, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    def handle_outliers(dataset):\n",
    "        # Note: Dropped columns are categorical features. There is no use to handle outliers for them.\n",
    "        for index, feature in enumerate(dataset.drop(columns=['Education', 'Geography', 'Gender', 'Card Type', 'IsActiveMember', 'HasCrCard', 'Housing', 'Loan', 'Exited'])):\n",
    "            Q1 = dataset[feature].quantile(0.25)\n",
    "            Q3 = dataset[feature].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            dataset[feature] = np.clip(dataset[feature], Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
    "          \n",
    "        return dataset;           \n",
    "\n",
    "    def handle_missing_values(dataset):\n",
    "        columns = dataset.columns.tolist()\n",
    "        for column in columns:\n",
    "            # Calculate null values and percentage\n",
    "            null_count = dataset[column].isnull().sum()\n",
    "            total_count = len(dataset[column])\n",
    "            null_percentage = (null_count / total_count) * 100\n",
    "\n",
    "            # Handle columns based on null percentage and data type\n",
    "            if null_percentage < 50:\n",
    "                # Fill missing values for numerical columns\n",
    "                if is_numeric_dtype(dataset[column]):\n",
    "                    mean = dataset[column].mean()\n",
    "                    dataset[column].fillna(mean, inplace=True)\n",
    "                # Fill missing values for categorical columns\n",
    "                elif is_object_dtype(dataset[column]):\n",
    "                    mode = dataset[column].mode()[0]\n",
    "                    dataset[column].fillna(mode, inplace=True)\n",
    "            # elif 50 <= null_percentage < 70:\n",
    "            #     # TODO: Implement the data missing data handling\n",
    "            #     print(f\"Under development for column: {column}\")\n",
    "            else:   \n",
    "                # Drop columns with more than 80% missing values\n",
    "                dataset.drop(columns=column, inplace=True)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def remove_duplicates(dataset):\n",
    "        if dataset.duplicated().sum() > 0:\n",
    "            dataset = dataset.drop_duplicates().reset_index(drop = True)\n",
    "        return dataset\n",
    "\n",
    "    def encode_categorical_features(dataset):\n",
    "        # One-Hot encoding\n",
    "        encoded = pd.get_dummies(dataset[['Geography','Education','Card Type']], drop_first=True).astype(float)\n",
    "        dataset = pd.concat([dataset, encoded], axis=1)\n",
    "        dataset = dataset.drop(columns=['Geography','Education', 'Card Type'])\n",
    "\n",
    "        # # Label encoding\n",
    "        labelEncoder = LabelEncoder()\n",
    "        dataset['Gender'] = labelEncoder.fit_transform(dataset['Gender'])\n",
    "        dataset['Housing'] = labelEncoder.fit_transform(dataset['Housing'])\n",
    "        dataset['Loan'] = labelEncoder.fit_transform(dataset['Loan'])\n",
    "\n",
    "        dataset['Gender'] = dataset['Gender'].astype(float)\n",
    "        dataset['Housing'] = dataset['Housing'].astype(float)\n",
    "        dataset['Loan'] = dataset['Loan'].astype(float)\n",
    "\n",
    "        # Moving the Y predictor to the end of the dataset\n",
    "        feature_exited = dataset['Exited']\n",
    "        dataset = dataset.drop(columns=['Exited'])\n",
    "        dataset = pd.concat([dataset, feature_exited], axis=1)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def split_dataset_to_X_y(dataset):\n",
    "        X = dataset.iloc[:, :-1]\n",
    "        y = dataset.iloc[:, -1]\n",
    "        return X, y\n",
    "\n",
    "    def handle_class_imbalance(X, y):\n",
    "        categorical_features = [\n",
    "            'Gender', \n",
    "            'HasCrCard', 'IsActiveMember', \n",
    "            'Housing', 'Loan','Geography_Germany', \n",
    "            'Geography_Spain', 'Education_secondary',\n",
    "            'Education_tertiary', 'Education_unknown', \n",
    "            'Card Type_GOLD','Card Type_None', \n",
    "            'Card Type_PLATINUM', 'Card Type_SILVER'\n",
    "        ]\n",
    "\n",
    "        cat_indices = [X.columns.get_loc(col) for col in categorical_features]\n",
    "        \n",
    "        smote = SMOTENC(categorical_features=cat_indices, k_neighbors=9, random_state=42)\n",
    "        overSampled_X, overSampled_y = smote.fit_resample(X, y)\n",
    "\n",
    "        return overSampled_X, overSampled_y  \n",
    "\n",
    "    def scale_features(X_train, X_test):\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test) \n",
    "        return X_train_scaled, X_test_scaled\n",
    "\n",
    "    # Removing irrelevant features\n",
    "    dataset = dataset.drop(columns= ['CustomerId', 'Surname'])\n",
    "\n",
    "    # Removing the white spaces from feature names\n",
    "    dataset.columns = dataset.columns.str.strip()\n",
    "\n",
    "    # Handling null values\n",
    "    dataset = handle_missing_values(dataset)\n",
    "\n",
    "    # Check and drop duplicates from the database\n",
    "    dataset =  remove_duplicates(dataset)\n",
    "\n",
    "    # Check and handle outliers from the database\n",
    "    dataset = handle_outliers(dataset)\n",
    "\n",
    "    # Encoding categorical features using one-hot encoding and label encoding\n",
    "    dataset = encode_categorical_features(dataset)\n",
    "\n",
    "    # Re-Removing the white spaces from feature names\n",
    "    dataset.columns = dataset.columns.str.strip()\n",
    "\n",
    "    # Splitting the dataset into X and y\n",
    "    X, y = split_dataset_to_X_y(dataset)\n",
    "\n",
    "    # Generating synthetic data using SMOTE\n",
    "    X, y = handle_class_imbalance(X, y)\n",
    "\n",
    "    # Splitting the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Feature scaling using min max scaler\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_grid_search(model, parameters, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, parameters)\n",
    "    return grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_random_search(model, params, n_tier, cv, X_train, y_train):\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=n_tier, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "    return random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'n_estimators': 413,\n",
       " 'reg_alpha': np.float64(0.5257564316322378),\n",
       " 'reg_lambda': np.float64(4.329450186421157)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "XGM = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    # random_state=42,\n",
    "    n_jobs=-1,\n",
    "    # max_depth= 7,\n",
    "    # n_estimators= 350,\n",
    "    # reg_alpha= 1,\n",
    "    # reg_lambda= 0.001,\n",
    ")\n",
    "\n",
    "# XGM.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "# params_XG = {\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'earning_rate': [0.1, 0.01, 0.001],\n",
    "#     'reg_alpha': [0, 0.1, 0.5, 1, 5, 10],\n",
    "#     'reg_lambda': [0.1, 0.01, 0.001],\n",
    "#     'n_estimators': [100, 200, 350, 400],\n",
    "#}\n",
    "# XGM = preform_grid_search(XGM, params_XG, X_train, y_train)\n",
    "\n",
    "params_XG = {\n",
    "    'max_depth': randint(2, 8),\n",
    "    'reg_alpha': uniform(0.001, 1),\n",
    "    'reg_lambda': uniform(0.01, 10),\n",
    "    'n_estimators': randint(100, 500),\n",
    "}\n",
    "\n",
    "XGM = preform_random_search(XGM, params_XG, 20, 5, X_train, y_train)\n",
    "XGM.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/best_XGboost.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(XGM.best_estimator_, \"./models/best_XGboost.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121155053358443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.94      0.92      1633\n",
      "         1.0       0.93      0.88      0.91      1553\n",
      "\n",
      "    accuracy                           0.91      3186\n",
      "   macro avg       0.91      0.91      0.91      3186\n",
      "weighted avg       0.91      0.91      0.91      3186\n",
      "\n",
      "[[1533  100]\n",
      " [ 180 1373]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_XG = XGM.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_XG))\n",
    "print(classification_report(y_test, y_pred_XG))\n",
    "print(confusion_matrix(y_test, y_pred_XG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6410, number of negative: 6330\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 12740, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503140 -> initscore=0.012559\n",
      "[LightGBM] [Info] Start training from score 0.012559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': np.float64(0.24202546602601172),\n",
       " 'max_depth': 8,\n",
       " 'num_leaves': 27}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB = lgb.LGBMClassifier()\n",
    "\n",
    "params_LGB = {\n",
    "    'learning_rate': uniform(0.001, 1),\n",
    "    'max_depth': randint(2, 20),\n",
    "    'num_leaves': randint(20, 60)\n",
    "}\n",
    "\n",
    "LGB = preform_random_search(LGB, params_LGB, 20, 5, X_train, y_train)\n",
    "LGB.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/best_lightgbm.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(LGB.best_estimator_, \"./models/best_lightgbm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127432517263026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92      1633\n",
      "         1.0       0.93      0.88      0.91      1553\n",
      "\n",
      "    accuracy                           0.91      3186\n",
      "   macro avg       0.91      0.91      0.91      3186\n",
      "weighted avg       0.91      0.91      0.91      3186\n",
      "\n",
      "[[1535   98]\n",
      " [ 180 1373]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_LGM = LGB.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_LGM))\n",
    "print(classification_report(y_test, y_pred_LGM))\n",
    "print(confusion_matrix(y_test, y_pred_LGM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 17, 'min_samples_split': 4}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(\n",
    "    n_estimators = 300\n",
    ")\n",
    "# RF.fit(X_train, y_train)\n",
    "\n",
    "# params_RF = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "# }\n",
    "\n",
    "params_RF = {\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 20)\n",
    "}\n",
    "\n",
    "# RF = preform_grid_search(RF, params_RF, X_train, y_train)\n",
    "RF = preform_random_search(RF, params_RF, 20, 10, X_train, y_train)\n",
    "RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/best_RandomForest_Classifier.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(RF.best_estimator_, \"./models/best_RandomForest_Classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9048964218455744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91      1633\n",
      "         1.0       0.93      0.87      0.90      1553\n",
      "\n",
      "    accuracy                           0.90      3186\n",
      "   macro avg       0.91      0.90      0.90      3186\n",
      "weighted avg       0.91      0.90      0.90      3186\n",
      "\n",
      "[[1525  108]\n",
      " [ 195 1358]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_RC = RF.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_RC))\n",
    "print(classification_report(y_test, y_pred_RC))\n",
    "print(confusion_matrix(y_test, y_pred_RC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6410, number of negative: 6330\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1558\n",
      "[LightGBM] [Info] Number of data points in the train set: 12740, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503140 -> initscore=0.012559\n",
      "[LightGBM] [Info] Start training from score 0.012559\n"
     ]
    }
   ],
   "source": [
    "votes = VotingClassifier(estimators=[('xg', XGM), ('lgb', LGB), ('rf', RF)], voting='soft')\n",
    "votes.fit(X_train, y_train)\n",
    "y_pred= votes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9158819836785939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92      1633\n",
      "         1.0       0.94      0.89      0.91      1553\n",
      "\n",
      "    accuracy                           0.92      3186\n",
      "   macro avg       0.92      0.92      0.92      3186\n",
      "weighted avg       0.92      0.92      0.92      3186\n",
      "\n",
      "[[1540   93]\n",
      " [ 175 1378]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
